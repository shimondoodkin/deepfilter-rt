searchState.loadedDescShard("deepfilter_rt", 0, "DeepFilter-RT\nReal-time DeepFilterNet processor\nStreaming wrapper with buffering\nContains the error value\nRuntime inference mode override.\nModel variant detection from config.ini\nContains the success value\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nDetect variant from config.ini in model directory\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nLatency in ms (10ms for LL variants, 30ms for standard)\nCreate processor from model directory\nCreate processor with explicit inference mode (for …\nCreate stream with explicit inference mode.\nProcess variable-length input\nProcess single frame (480 samples @ 48kHz = 10ms)\nGet mutable access to the underlying processor\nPerform warm-up inference to avoid cold-start latency\nPerform warm-up inference to avoid cold-start latency\nCreate stream with explicit thread count\nCreate processor with explicit variant\nCreate processor with explicit variant and thread count\nCreate processor with explicit variant, mode, and thread …")